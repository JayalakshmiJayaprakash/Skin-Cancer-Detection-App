{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(os.getcwd(), 'HAM10000_Images')\n",
    "for dirname, _, _ in os.walk(base_path):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in: d:\\term 4\\Studio\\Skin\\Skin-Cancer-Detection-App\\Ml_Model\\data\\HAM10000_Images\n",
      "Directories found: ['d:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images', 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\akiec', 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\bcc', 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\bkl', 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\df', 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\mel', 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\nv', 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\vasc']\n",
      "Number of files: 10022\n"
     ]
    }
   ],
   "source": [
    "base_path = r\"d:\\term 4\\Studio\\Skin\\Skin-Cancer-Detection-App\\Ml_Model\\data\\HAM10000_Images\"\n",
    "print(\"Looking in:\", base_path)\n",
    "\n",
    "d_paths = [x[0] for x in os.walk(base_path)]\n",
    "print(\"Directories found:\", d_paths)\n",
    "\n",
    "i_paths = []\n",
    "for d_path in d_paths:\n",
    "    i_paths.extend(glob(os.path.join(d_path, '*')))\n",
    "print(\"Number of files:\", len(i_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images',\n",
       " 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\akiec',\n",
       " 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\bcc',\n",
       " 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\bkl',\n",
       " 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\df',\n",
       " 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\mel',\n",
       " 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\nv',\n",
       " 'd:\\\\term 4\\\\Studio\\\\Skin\\\\Skin-Cancer-Detection-App\\\\Ml_Model\\\\data\\\\HAM10000_Images\\\\vasc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'none': 7, 'jpg': 10015}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wolta.visual_tools import get_extensions\n",
    "\n",
    "get_extensions(i_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images found: 10015\n",
      "First image path: d:\\term 4\\Studio\\Skin\\Skin-Cancer-Detection-App\\Ml_Model\\data\\HAM10000_Images\\akiec\\ISIC_0024329.jpg\n",
      "width: 128\n",
      "height: 128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i_paths = []\n",
    "for subfolder in ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']:\n",
    "    folder_path = os.path.join(base_path, subfolder)\n",
    "    image_paths = glob(os.path.join(folder_path, '*.*'))  # Get all files\n",
    "    i_paths.extend(image_paths)\n",
    "\n",
    "# Print first few paths to verify\n",
    "print(\"Number of images found:\", len(i_paths))\n",
    "if len(i_paths) > 0:\n",
    "    print(\"First image path:\", i_paths[0])\n",
    "    # Try reading the first image\n",
    "    img = cv2.imread(i_paths[0])\n",
    "    if img is not None:\n",
    "        print('width: {}\\nheight: {}'.format(img.shape[1], img.shape[0]))\n",
    "    else:\n",
    "        print(\"Failed to read image\")\n",
    "else:\n",
    "    print(\"No images found in the directories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img, crop_width, crop_height):\n",
    "    \"\"\"Crop the center of an image.\"\"\"\n",
    "    h, w, _ = img.shape\n",
    "    start_x = max((w - crop_width) // 2, 0)\n",
    "    start_y = max((h - crop_height) // 2, 0)\n",
    "    return img[start_y:start_y + crop_height, start_x:start_x + crop_width]\n",
    "\n",
    "# Create a directory for processed images\n",
    "output_base = 'processed_images'\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# Get all subdirectories in HAM10000_Images\n",
    "base_path = r\"d:\\term 4\\Studio\\Skin\\Skin-Cancer-Detection-App\\Ml_Model\\data\\HAM10000_Images\"\n",
    "d_paths = [os.path.join(base_path, d) for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "\n",
    "for d_path in d_paths:\n",
    "    # Get directory name from path\n",
    "    dir_name = os.path.basename(d_path)\n",
    "    \n",
    "    # Create subdirectory for each class\n",
    "    current_dir = os.path.join(output_base, dir_name)\n",
    "    os.makedirs(current_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all images in current directory\n",
    "    i_paths = glob(os.path.join(d_path, '*'))\n",
    "    \n",
    "    for i_path in i_paths:\n",
    "        # Get image name\n",
    "        i_name = os.path.basename(i_path)\n",
    "        \n",
    "        # Read and process image\n",
    "        img = cv2.imread(i_path)\n",
    "        if img is not None:\n",
    "            edge = min(img.shape[0], img.shape[1])\n",
    "            img = crop_center(img, edge, edge)\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            \n",
    "            # Save processed image\n",
    "            output_path = os.path.join(current_dir, i_name)\n",
    "            try:\n",
    "                cv2.imwrite(output_path, img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving image: {output_path}\")\n",
    "                print(e)\n",
    "        else:\n",
    "            print(f\"Failed to read image: {i_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPARATION FOR TESTING AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10015 files belonging to 7 classes.\n",
      "Using 6009 files for training.\n",
      "Using 4006 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'processed_images',\n",
    "    validation_split=0.4,\n",
    "    subset='both',\n",
    "    seed=123,\n",
    "    image_size=(128, 128),\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val_ds_size = tf.data.experimental.cardinality(test_val_ds).numpy()\n",
    "test_val_split_size = int(0.5 * test_val_ds_size)\n",
    "\n",
    "validation_ds = test_val_ds.take(test_val_split_size)\n",
    "test_ds = test_val_ds.skip(test_val_split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n"
     ]
    }
   ],
   "source": [
    "names = train_ds.class_names\n",
    "num_classes = len(names)\n",
    "\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Input(shape=[128, 128, 3]),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m2,097,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,121,767</span> (8.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,121,767\u001b[0m (8.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,121,767</span> (8.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,121,767\u001b[0m (8.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.6477 - loss: 1.1629 - val_accuracy: 0.6780 - val_loss: 0.9292\n",
      "Epoch 2/5\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 57ms/step - accuracy: 0.6627 - loss: 0.9661 - val_accuracy: 0.6755 - val_loss: 0.9425\n",
      "Epoch 3/5\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.6755 - loss: 0.9002 - val_accuracy: 0.6910 - val_loss: 0.8726\n",
      "Epoch 4/5\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.6879 - loss: 0.8459 - val_accuracy: 0.7115 - val_loss: 0.7986\n",
      "Epoch 5/5\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 59ms/step - accuracy: 0.7051 - loss: 0.7918 - val_accuracy: 0.7250 - val_loss: 0.7677\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"data/skin_cancer_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.7504 - loss: 0.7169\n",
      "Test Accuracy: 72.43%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Test Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "Image: ISIC_0024308.jpg | Predicted: mel | Confidence: 13.32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Image: ISIC_0024371.jpg | Predicted: mel | Confidence: 13.32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Image: ISIC_0024418.jpg | Predicted: mel | Confidence: 13.29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Image: ISIC_0024457.jpg | Predicted: mel | Confidence: 13.30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Image: ISIC_0024459.jpg | Predicted: mel | Confidence: 13.39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Image: ISIC_0024904.jpg | Predicted: mel | Confidence: 13.31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Image: ISIC_0024973.jpg | Predicted: mel | Confidence: 13.33\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"data/skin_cancer_model.keras\")\n",
    "\n",
    "# Define class labels (ensure these match your dataset labels)\n",
    "class_labels = [\"akiec\", \"bcc\", \"bkl\", \"df\", \"mel\", \"nv\", \"vasc\"]\n",
    "\n",
    "# Path to test images\n",
    "test_folder = \"data/test\"\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess the image for model prediction\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (128, 128))  # Resize to match your model's input size\n",
    "    img = img / 255.0  # Normalize pixel values\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "def predict_image(image_path):\n",
    "    \"\"\"Predict the class of the image\"\"\"\n",
    "    img = preprocess_image(image_path)\n",
    "    prediction = model.predict(img)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    return class_labels[predicted_class], prediction[0][predicted_class]\n",
    "\n",
    "# Iterate through test images and predict\n",
    "for image_name in os.listdir(test_folder):\n",
    "    image_path = os.path.join(test_folder, image_name)\n",
    "    predicted_class, confidence = predict_image(image_path)\n",
    "    print(f\"Image: {image_name} | Predicted: {predicted_class} | Confidence: {confidence:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - accuracy: 0.6520 - loss: 1.1182 - val_accuracy: 0.6680 - val_loss: 0.9408\n",
      "Epoch 2/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.6687 - loss: 0.9244 - val_accuracy: 0.6775 - val_loss: 0.8544\n",
      "Epoch 3/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.6729 - loss: 0.8829 - val_accuracy: 0.6860 - val_loss: 0.8595\n",
      "Epoch 4/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.6865 - loss: 0.8532 - val_accuracy: 0.7039 - val_loss: 0.7870\n",
      "Epoch 5/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.6982 - loss: 0.8047 - val_accuracy: 0.7034 - val_loss: 0.7974\n",
      "Epoch 6/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.6929 - loss: 0.8254 - val_accuracy: 0.7319 - val_loss: 0.7245\n",
      "Epoch 7/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.7281 - loss: 0.7419 - val_accuracy: 0.7109 - val_loss: 0.7542\n",
      "Epoch 8/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7254 - loss: 0.7079 - val_accuracy: 0.7319 - val_loss: 0.7560\n",
      "Epoch 9/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.7372 - loss: 0.6874 - val_accuracy: 0.7534 - val_loss: 0.6802\n",
      "Epoch 10/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7388 - loss: 0.6798 - val_accuracy: 0.7369 - val_loss: 0.6951\n",
      "Epoch 11/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7479 - loss: 0.6599 - val_accuracy: 0.7544 - val_loss: 0.6742\n",
      "Epoch 12/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7630 - loss: 0.6431 - val_accuracy: 0.7504 - val_loss: 0.6983\n",
      "Epoch 13/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.7660 - loss: 0.6172 - val_accuracy: 0.7439 - val_loss: 0.7200\n",
      "Epoch 14/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.7720 - loss: 0.6096 - val_accuracy: 0.7539 - val_loss: 0.6507\n",
      "Epoch 15/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.7779 - loss: 0.5913 - val_accuracy: 0.7434 - val_loss: 0.7024\n",
      "Epoch 16/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.7824 - loss: 0.5612 - val_accuracy: 0.7594 - val_loss: 0.6711\n",
      "Epoch 17/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.7879 - loss: 0.5499 - val_accuracy: 0.7649 - val_loss: 0.6711\n",
      "Epoch 18/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.8034 - loss: 0.5275 - val_accuracy: 0.7619 - val_loss: 0.7130\n",
      "Epoch 19/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.8059 - loss: 0.5060 - val_accuracy: 0.7723 - val_loss: 0.6828\n",
      "Epoch 20/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.8209 - loss: 0.4645 - val_accuracy: 0.7629 - val_loss: 0.6980\n",
      "Epoch 21/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.8160 - loss: 0.4831 - val_accuracy: 0.7624 - val_loss: 0.7726\n",
      "Epoch 22/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.8305 - loss: 0.4583 - val_accuracy: 0.7494 - val_loss: 0.7889\n",
      "Epoch 23/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.8425 - loss: 0.4277 - val_accuracy: 0.7549 - val_loss: 0.7294\n",
      "Epoch 24/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.8335 - loss: 0.4324 - val_accuracy: 0.7599 - val_loss: 0.7209\n",
      "Epoch 25/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.8547 - loss: 0.3742 - val_accuracy: 0.7654 - val_loss: 0.7666\n",
      "Epoch 26/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.8588 - loss: 0.3627 - val_accuracy: 0.7634 - val_loss: 0.7949\n",
      "Epoch 27/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.8551 - loss: 0.3744 - val_accuracy: 0.7723 - val_loss: 0.9043\n",
      "Epoch 28/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.8607 - loss: 0.3448 - val_accuracy: 0.7683 - val_loss: 0.8429\n",
      "Epoch 29/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.8716 - loss: 0.3175 - val_accuracy: 0.7564 - val_loss: 0.9060\n",
      "Epoch 30/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.8806 - loss: 0.3061 - val_accuracy: 0.7594 - val_loss: 1.0143\n",
      "Epoch 31/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.8932 - loss: 0.2823 - val_accuracy: 0.7609 - val_loss: 0.9245\n",
      "Epoch 32/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.8871 - loss: 0.2947 - val_accuracy: 0.7609 - val_loss: 0.9798\n",
      "Epoch 33/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.8943 - loss: 0.2663 - val_accuracy: 0.7708 - val_loss: 0.9512\n",
      "Epoch 34/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.8952 - loss: 0.2610 - val_accuracy: 0.7668 - val_loss: 0.9615\n",
      "Epoch 35/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9106 - loss: 0.2289 - val_accuracy: 0.7644 - val_loss: 0.9856\n",
      "Epoch 36/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9145 - loss: 0.2213 - val_accuracy: 0.7434 - val_loss: 1.3855\n",
      "Epoch 37/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9034 - loss: 0.2498 - val_accuracy: 0.7703 - val_loss: 1.2390\n",
      "Epoch 38/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.9104 - loss: 0.2268 - val_accuracy: 0.7489 - val_loss: 1.2119\n",
      "Epoch 39/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - accuracy: 0.9148 - loss: 0.2259 - val_accuracy: 0.7559 - val_loss: 1.0307\n",
      "Epoch 40/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9227 - loss: 0.1996 - val_accuracy: 0.7624 - val_loss: 1.2562\n",
      "Epoch 41/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9313 - loss: 0.1810 - val_accuracy: 0.7688 - val_loss: 1.2559\n",
      "Epoch 42/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9341 - loss: 0.1644 - val_accuracy: 0.7748 - val_loss: 1.1838\n",
      "Epoch 43/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.9278 - loss: 0.1777 - val_accuracy: 0.7584 - val_loss: 1.4884\n",
      "Epoch 44/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9289 - loss: 0.1908 - val_accuracy: 0.7668 - val_loss: 1.3148\n",
      "Epoch 45/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.9294 - loss: 0.1897 - val_accuracy: 0.7629 - val_loss: 1.3521\n",
      "Epoch 46/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9346 - loss: 0.1588 - val_accuracy: 0.7609 - val_loss: 1.3883\n",
      "Epoch 47/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9346 - loss: 0.1668 - val_accuracy: 0.7579 - val_loss: 1.4368\n",
      "Epoch 48/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9517 - loss: 0.1214 - val_accuracy: 0.7559 - val_loss: 1.5603\n",
      "Epoch 49/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9373 - loss: 0.1505 - val_accuracy: 0.7649 - val_loss: 1.3383\n",
      "Epoch 50/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9381 - loss: 0.1546 - val_accuracy: 0.7589 - val_loss: 1.4120\n",
      "Epoch 51/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9467 - loss: 0.1334 - val_accuracy: 0.7664 - val_loss: 1.5739\n",
      "Epoch 52/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9461 - loss: 0.1447 - val_accuracy: 0.7654 - val_loss: 1.5615\n",
      "Epoch 53/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9497 - loss: 0.1221 - val_accuracy: 0.7723 - val_loss: 1.6021\n",
      "Epoch 54/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9476 - loss: 0.1326 - val_accuracy: 0.7688 - val_loss: 1.7087\n",
      "Epoch 55/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9432 - loss: 0.1451 - val_accuracy: 0.7688 - val_loss: 1.3995\n",
      "Epoch 56/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9611 - loss: 0.1119 - val_accuracy: 0.7644 - val_loss: 1.6263\n",
      "Epoch 57/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9534 - loss: 0.1205 - val_accuracy: 0.7629 - val_loss: 1.7513\n",
      "Epoch 58/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - accuracy: 0.9505 - loss: 0.1274 - val_accuracy: 0.7668 - val_loss: 1.5859\n",
      "Epoch 59/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9606 - loss: 0.1021 - val_accuracy: 0.7624 - val_loss: 1.7402\n",
      "Epoch 60/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9634 - loss: 0.0995 - val_accuracy: 0.7584 - val_loss: 1.6740\n",
      "Epoch 61/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9576 - loss: 0.1128 - val_accuracy: 0.7654 - val_loss: 1.6842\n",
      "Epoch 62/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9568 - loss: 0.1146 - val_accuracy: 0.7644 - val_loss: 1.9167\n",
      "Epoch 63/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9582 - loss: 0.1079 - val_accuracy: 0.7723 - val_loss: 1.7733\n",
      "Epoch 64/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9485 - loss: 0.1349 - val_accuracy: 0.7599 - val_loss: 1.6441\n",
      "Epoch 65/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9601 - loss: 0.1172 - val_accuracy: 0.7644 - val_loss: 1.8443\n",
      "Epoch 66/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9637 - loss: 0.0963 - val_accuracy: 0.7539 - val_loss: 1.8548\n",
      "Epoch 67/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9697 - loss: 0.0782 - val_accuracy: 0.7564 - val_loss: 1.9642\n",
      "Epoch 68/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9653 - loss: 0.0896 - val_accuracy: 0.7649 - val_loss: 1.7950\n",
      "Epoch 69/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9713 - loss: 0.0828 - val_accuracy: 0.7449 - val_loss: 1.9721\n",
      "Epoch 70/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9610 - loss: 0.1137 - val_accuracy: 0.7569 - val_loss: 1.7919\n",
      "Epoch 71/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9683 - loss: 0.0899 - val_accuracy: 0.7659 - val_loss: 2.0244\n",
      "Epoch 72/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9607 - loss: 0.1069 - val_accuracy: 0.7534 - val_loss: 2.0190\n",
      "Epoch 73/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - accuracy: 0.9572 - loss: 0.1057 - val_accuracy: 0.7609 - val_loss: 1.9704\n",
      "Epoch 74/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9713 - loss: 0.0865 - val_accuracy: 0.7584 - val_loss: 2.3307\n",
      "Epoch 75/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9618 - loss: 0.1008 - val_accuracy: 0.7668 - val_loss: 1.9217\n",
      "Epoch 76/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9664 - loss: 0.0910 - val_accuracy: 0.7574 - val_loss: 2.0074\n",
      "Epoch 77/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 41ms/step - accuracy: 0.9674 - loss: 0.0802 - val_accuracy: 0.7524 - val_loss: 2.3041\n",
      "Epoch 78/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9524 - loss: 0.1234 - val_accuracy: 0.7539 - val_loss: 2.0736\n",
      "Epoch 79/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9697 - loss: 0.0788 - val_accuracy: 0.7639 - val_loss: 1.9506\n",
      "Epoch 80/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9473 - loss: 0.1361 - val_accuracy: 0.7594 - val_loss: 2.2335\n",
      "Epoch 81/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9675 - loss: 0.0863 - val_accuracy: 0.7579 - val_loss: 2.3039\n",
      "Epoch 82/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9655 - loss: 0.1004 - val_accuracy: 0.7668 - val_loss: 2.4576\n",
      "Epoch 83/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9679 - loss: 0.0829 - val_accuracy: 0.7649 - val_loss: 2.1653\n",
      "Epoch 84/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9691 - loss: 0.0819 - val_accuracy: 0.7604 - val_loss: 2.3840\n",
      "Epoch 85/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9709 - loss: 0.0747 - val_accuracy: 0.7574 - val_loss: 2.5607\n",
      "Epoch 86/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9657 - loss: 0.0924 - val_accuracy: 0.7554 - val_loss: 2.2505\n",
      "Epoch 87/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.9692 - loss: 0.0807 - val_accuracy: 0.7584 - val_loss: 2.5636\n",
      "Epoch 88/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9693 - loss: 0.0923 - val_accuracy: 0.7564 - val_loss: 2.1602\n",
      "Epoch 89/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9711 - loss: 0.0830 - val_accuracy: 0.7649 - val_loss: 2.5326\n",
      "Epoch 90/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9742 - loss: 0.0736 - val_accuracy: 0.7624 - val_loss: 2.3373\n",
      "Epoch 91/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9757 - loss: 0.0749 - val_accuracy: 0.7589 - val_loss: 2.2400\n",
      "Epoch 92/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9694 - loss: 0.0842 - val_accuracy: 0.7649 - val_loss: 2.4153\n",
      "Epoch 93/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9640 - loss: 0.1020 - val_accuracy: 0.7659 - val_loss: 2.4049\n",
      "Epoch 94/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9740 - loss: 0.0766 - val_accuracy: 0.7569 - val_loss: 2.1711\n",
      "Epoch 95/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.9705 - loss: 0.0800 - val_accuracy: 0.7678 - val_loss: 2.3241\n",
      "Epoch 96/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 42ms/step - accuracy: 0.9704 - loss: 0.0769 - val_accuracy: 0.7589 - val_loss: 2.2406\n",
      "Epoch 97/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9781 - loss: 0.0607 - val_accuracy: 0.7549 - val_loss: 2.3901\n",
      "Epoch 98/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9731 - loss: 0.0751 - val_accuracy: 0.7664 - val_loss: 2.3165\n",
      "Epoch 99/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9759 - loss: 0.0672 - val_accuracy: 0.7569 - val_loss: 2.4094\n",
      "Epoch 100/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9702 - loss: 0.0824 - val_accuracy: 0.7639 - val_loss: 2.4702\n",
      "Epoch 101/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9751 - loss: 0.0651 - val_accuracy: 0.7614 - val_loss: 2.4878\n",
      "Epoch 102/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9772 - loss: 0.0629 - val_accuracy: 0.7564 - val_loss: 2.6013\n",
      "Epoch 103/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9752 - loss: 0.0759 - val_accuracy: 0.7614 - val_loss: 2.2543\n",
      "Epoch 104/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9738 - loss: 0.0771 - val_accuracy: 0.7599 - val_loss: 2.5057\n",
      "Epoch 105/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9701 - loss: 0.0774 - val_accuracy: 0.7619 - val_loss: 2.2439\n",
      "Epoch 106/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9725 - loss: 0.0743 - val_accuracy: 0.7579 - val_loss: 2.4543\n",
      "Epoch 107/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9741 - loss: 0.0733 - val_accuracy: 0.7444 - val_loss: 2.8189\n",
      "Epoch 108/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9758 - loss: 0.0716 - val_accuracy: 0.7459 - val_loss: 2.3528\n",
      "Epoch 109/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9717 - loss: 0.0788 - val_accuracy: 0.7589 - val_loss: 2.5088\n",
      "Epoch 110/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9724 - loss: 0.0721 - val_accuracy: 0.7509 - val_loss: 2.5128\n",
      "Epoch 111/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9745 - loss: 0.0643 - val_accuracy: 0.7539 - val_loss: 2.5312\n",
      "Epoch 112/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9794 - loss: 0.0564 - val_accuracy: 0.7479 - val_loss: 2.6670\n",
      "Epoch 113/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9752 - loss: 0.0706 - val_accuracy: 0.7629 - val_loss: 2.7174\n",
      "Epoch 114/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.9681 - loss: 0.0971 - val_accuracy: 0.7489 - val_loss: 2.4753\n",
      "Epoch 115/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9720 - loss: 0.0719 - val_accuracy: 0.7544 - val_loss: 2.6723\n",
      "Epoch 116/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 43ms/step - accuracy: 0.9829 - loss: 0.0465 - val_accuracy: 0.7504 - val_loss: 2.5290\n",
      "Epoch 117/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9841 - loss: 0.0493 - val_accuracy: 0.7524 - val_loss: 2.9061\n",
      "Epoch 118/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9747 - loss: 0.0773 - val_accuracy: 0.7614 - val_loss: 2.8274\n",
      "Epoch 119/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9650 - loss: 0.1038 - val_accuracy: 0.7524 - val_loss: 2.5832\n",
      "Epoch 120/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9781 - loss: 0.0570 - val_accuracy: 0.7524 - val_loss: 2.9084\n",
      "Epoch 121/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9806 - loss: 0.0536 - val_accuracy: 0.7688 - val_loss: 3.0440\n",
      "Epoch 122/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9772 - loss: 0.0664 - val_accuracy: 0.7599 - val_loss: 2.9017\n",
      "Epoch 123/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9718 - loss: 0.0750 - val_accuracy: 0.7544 - val_loss: 2.6175\n",
      "Epoch 124/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9758 - loss: 0.0691 - val_accuracy: 0.7559 - val_loss: 2.7700\n",
      "Epoch 125/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9836 - loss: 0.0505 - val_accuracy: 0.7479 - val_loss: 2.8213\n",
      "Epoch 126/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9759 - loss: 0.0698 - val_accuracy: 0.7569 - val_loss: 2.9114\n",
      "Epoch 127/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9809 - loss: 0.0519 - val_accuracy: 0.7544 - val_loss: 2.8001\n",
      "Epoch 128/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9668 - loss: 0.0981 - val_accuracy: 0.7564 - val_loss: 2.6852\n",
      "Epoch 129/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9760 - loss: 0.0656 - val_accuracy: 0.7584 - val_loss: 2.6132\n",
      "Epoch 130/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9808 - loss: 0.0534 - val_accuracy: 0.7529 - val_loss: 2.6088\n",
      "Epoch 131/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.9674 - loss: 0.1010 - val_accuracy: 0.7644 - val_loss: 2.6397\n",
      "Epoch 132/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9781 - loss: 0.0551 - val_accuracy: 0.7594 - val_loss: 2.7649\n",
      "Epoch 133/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.9712 - loss: 0.0866 - val_accuracy: 0.7549 - val_loss: 2.9094\n",
      "Epoch 134/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9830 - loss: 0.0537 - val_accuracy: 0.7509 - val_loss: 3.1708\n",
      "Epoch 135/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9808 - loss: 0.0512 - val_accuracy: 0.7574 - val_loss: 3.4229\n",
      "Epoch 136/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9781 - loss: 0.0601 - val_accuracy: 0.7589 - val_loss: 3.1891\n",
      "Epoch 137/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9774 - loss: 0.0559 - val_accuracy: 0.7484 - val_loss: 2.8389\n",
      "Epoch 138/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9806 - loss: 0.0576 - val_accuracy: 0.7394 - val_loss: 2.8776\n",
      "Epoch 139/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9798 - loss: 0.0533 - val_accuracy: 0.7534 - val_loss: 2.8791\n",
      "Epoch 140/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9834 - loss: 0.0438 - val_accuracy: 0.7509 - val_loss: 2.7329\n",
      "Epoch 141/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.9764 - loss: 0.0694 - val_accuracy: 0.7484 - val_loss: 2.6598\n",
      "Epoch 142/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9825 - loss: 0.0476 - val_accuracy: 0.7539 - val_loss: 2.8327\n",
      "Epoch 143/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9829 - loss: 0.0518 - val_accuracy: 0.7514 - val_loss: 3.3504\n",
      "Epoch 144/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9803 - loss: 0.0588 - val_accuracy: 0.7639 - val_loss: 2.9253\n",
      "Epoch 145/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.9808 - loss: 0.0545 - val_accuracy: 0.7519 - val_loss: 2.9748\n",
      "Epoch 146/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9756 - loss: 0.0799 - val_accuracy: 0.7439 - val_loss: 2.8723\n",
      "Epoch 147/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.9742 - loss: 0.0732 - val_accuracy: 0.7594 - val_loss: 3.3945\n",
      "Epoch 148/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9830 - loss: 0.0480 - val_accuracy: 0.7609 - val_loss: 3.1234\n",
      "Epoch 149/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.9822 - loss: 0.0540 - val_accuracy: 0.7494 - val_loss: 3.1398\n",
      "Epoch 150/150\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9820 - loss: 0.0557 - val_accuracy: 0.7594 - val_loss: 3.1157\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7478 - loss: 3.2042\n",
      "Test Accuracy: 75.94%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load metadata\n",
    "metadata_path = r\"data/ImageData/HAM10000_metadata.csv\"\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Define image directory (update this path accordingly)\n",
    "image_dir = r\"data/ImageData/HAM10000_images_part_1\"\n",
    "\n",
    "# Load and preprocess images\n",
    "img_size = 64  # Resize images to 64x64\n",
    "\n",
    "def load_images(metadata, img_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {label: idx for idx, label in enumerate(metadata['dx'].unique())}  # Encoding labels\n",
    "    \n",
    "    for index, row in metadata.iterrows():\n",
    "        img_path = os.path.join(image_dir, row['image_id'] + \".jpg\")\n",
    "        if os.path.exists(img_path):\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "            img = img / 255.0  # Normalize\n",
    "            images.append(img)\n",
    "            labels.append(label_map[row['dx']])\n",
    "    \n",
    "    return np.array(images), np.array(labels), label_map\n",
    "\n",
    "# Load dataset\n",
    "X, y, label_map = load_images(metadata, img_size)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define CNN model\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create and train model\n",
    "model = create_cnn_model((img_size, img_size, 3), len(label_map))\n",
    "model.fit(X_train, y_train, epochs=150, validation_data=(X_test, y_test), batch_size=32)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save(r\"data/skin_cancer_cnn.keras\")\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "Image: ISIC_0024319NV.jpg --> Predicted Skin Cancer Type: bcc\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Image: ISIC_0024403BC.jpg --> Predicted Skin Cancer Type: nv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Image: ISIC_0024412BKL.jpg --> Predicted Skin Cancer Type: bcc\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Image: ISIC_0024459ML.jpg --> Predicted Skin Cancer Type: df\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Image: ISIC_0024575A.jpg --> Predicted Skin Cancer Type: vasc\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Image: ISIC_0025606VA.jpg --> Predicted Skin Cancer Type: mel\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Image: ISIC_0025622DF.jpg --> Predicted Skin Cancer Type: bkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"data/skin_cancer_cnn.keras\"  # Update if saved elsewhere\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Define image size (should match training size)\n",
    "img_size = 64  \n",
    "\n",
    "# Load label mapping (update based on training)\n",
    "label_map = {\n",
    "    0: \"akiec\",  # Actinic keratoses\n",
    "    1: \"bcc\",    # Basal cell carcinoma\n",
    "    2: \"bkl\",    # Benign keratosis-like lesions\n",
    "    3: \"df\",     # Dermatofibroma\n",
    "    4: \"mel\",    # Melanoma\n",
    "    5: \"nv\",     # Melanocytic nevi\n",
    "    6: \"vasc\"    # Vascular lesions\n",
    "}\n",
    "\n",
    "# Directory containing test images\n",
    "test_dir = r\"data/test\"\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Error loading image: {img_path}\")\n",
    "        return None\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    img = img / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Predict on all test images\n",
    "for filename in os.listdir(test_dir):\n",
    "    img_path = os.path.join(test_dir, filename)\n",
    "    img_array = preprocess_image(img_path)\n",
    "\n",
    "    if img_array is not None:\n",
    "        prediction = model.predict(img_array)\n",
    "        predicted_class = np.argmax(prediction)  # Get highest probability class\n",
    "        predicted_label = label_map[predicted_class]  # Converting index to class name\n",
    "        \n",
    "        print(f\"Image: {filename} --> Predicted Skin Cancer Type: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
